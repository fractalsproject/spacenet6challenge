{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SpaceNet6Challenge_Baseline_EvalSAR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMgbgRdzhkf5blwWWrL0MJd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fractalsproject/spacenet6challenge/blob/master/notebooks/SpaceNet6Challenge_Baseline_EvalSAR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuKrbBroRrCb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "# Config\n",
        "#\n",
        "\n",
        "# Force cloning a fresh repo\n",
        "force_clone = True\n",
        "\n",
        "# Top-level directory of pretest/pretain preproc artifacts\n",
        "pretrain_path = '/content/mountOnColab/pretrain'\n",
        "\n",
        "# Top-level directory of training sessions\n",
        "train_sessions_path = '/content/mountOnColab/train_sessions'\n",
        "\n",
        "# Where to get the yaml and csv templates\n",
        "configs_path = './spacenet6challenge/configs'\n",
        "\n",
        "# The (string) date of the training session\n",
        "session_date = '2020-05-06_15_34_04.994493' \n",
        "\n",
        "# The name of the weights file to load\n",
        "weights_file_name = 'best_epoch1_1.159000039100647.model'\n",
        "\n",
        "# Set to True if adding/changing solaris code in this Colab session\n",
        "reinstall_solaris = False\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVCZ1zisFRzZ",
        "colab_type": "code",
        "outputId": "2024256b-f024-4f44-c3f2-d5729ba9e588",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "# Clone the spacenet6challenge project\n",
        "if force_clone:\n",
        "  print(\"Removing local 'spacenet6challenge' repo if it exists\")\n",
        "  !if [ -d \"spacenet6challenge\" ]; then rm -r \"spacenet6challenge\"; fi\n",
        "!if [ ! -d \"spacenet6challenge\" ]; then git clone --recursive \"https://github.com/fractalsproject/spacenet6challenge.git\" ; else echo \"spacenet6challenge directory already exists\"; fi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Removing local 'spacenet6challenge' repo if it exists\n",
            "Cloning into 'spacenet6challenge'...\n",
            "remote: Enumerating objects: 188, done.\u001b[K\n",
            "remote: Counting objects: 100% (188/188), done.\u001b[K\n",
            "remote: Compressing objects: 100% (140/140), done.\u001b[K\n",
            "remote: Total 507 (delta 113), reused 113 (delta 46), pack-reused 319\u001b[K\n",
            "Receiving objects: 100% (507/507), 134.29 KiB | 2.69 MiB/s, done.\n",
            "Resolving deltas: 100% (245/245), done.\n",
            "Submodule 'CosmiQ_SN6_Baseline' (https://github.com/CosmiQ/CosmiQ_SN6_Baseline/) registered for path 'CosmiQ_SN6_Baseline'\n",
            "Submodule 'solaris' (https://github.com/fractalsproject/solaris.git) registered for path 'solaris'\n",
            "Cloning into '/content/spacenet6challenge/CosmiQ_SN6_Baseline'...\n",
            "remote: Enumerating objects: 323, done.        \n",
            "remote: Total 323 (delta 0), reused 0 (delta 0), pack-reused 323        \n",
            "Receiving objects: 100% (323/323), 81.24 MiB | 35.10 MiB/s, done.\n",
            "Resolving deltas: 100% (187/187), done.\n",
            "Cloning into '/content/spacenet6challenge/solaris'...\n",
            "remote: Enumerating objects: 5, done.        \n",
            "remote: Counting objects: 100% (5/5), done.        \n",
            "remote: Compressing objects: 100% (5/5), done.        \n",
            "remote: Total 3951 (delta 0), reused 1 (delta 0), pack-reused 3946        \n",
            "Receiving objects: 100% (3951/3951), 21.84 MiB | 17.95 MiB/s, done.\n",
            "Resolving deltas: 100% (2490/2490), done.\n",
            "Submodule path 'CosmiQ_SN6_Baseline': checked out 'afe2d88a9e0d41685f5d717a559024e86d2935c3'\n",
            "Submodule path 'solaris': checked out 'a1163bc4d322af7253b2ca220f68d80f6a0189e7'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8K270sGLj3E",
        "colab_type": "code",
        "outputId": "4e78a560-549e-431f-d927-513acc2437ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Check if we need to do a full package installation\n",
        "try:\n",
        "  import solaris\n",
        "  from solaris import utils\n",
        "  print(\"Found solaris package.  Assuming a previous installation worked.\")\n",
        "  solaris_ok = True\n",
        "except:\n",
        "  import sys\n",
        "  sys.path.append('/content/spacenet6challenge')\n",
        "  import spacenet6.colab.setup\n",
        "  spacenet6.colab.setup.baseline_prereqs(force=True)\n",
        "  solaris_ok = False"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking for jupyter/ipython environment...\n",
            "Passed.\n",
            "Checking for Colab environment...\n",
            "Passed.\n",
            "CMDS ['sudo apt-get install -y software-properties-common ', 'sudo add-apt-repository -y ppa:ubuntugis/ppa && apt-get -y update', 'sudo apt-get install -y libspatialindex-dev python-rtree gdal-bin', 'sudo apt-get install -y build-essential libssl-dev libffi-dev libxml2-dev libxslt1-dev zlib1g-dev', 'sudo apt-get install -y libgdal-dev ', 'sudo gdal-config --version ', 'pip install affine>=2.3.0 ', 'pip install albumentations==0.4.3', 'pip install fiona>=1.7.13 ', 'pip install geopandas>=0.7.0', 'pip install matplotlib>=3.1.2', 'pip install networkx>=2.4 ', 'pip install opencv-python>=4.1', 'pip install pandas>=0.25.3 ', 'pip install pyproj>=2.1 ', 'pip install pyyaml==5.2', 'pip install rasterio>=1.0.23', 'pip install requests==2.22.0', 'pip install rtree>=0.9.3 ', 'pip install scikit-image>=0.16.2', 'pip install scipy>=1.3.2 ', 'pip install torchvision>=0.5.0', 'pip install tqdm>=4.40.0 ', 'pip install urllib3>=1.25.7', 'pip install gdal>=3.0.2 ', 'pip install tensorflow-gpu==1.13.1'] True\n",
            "Running command: \"sudo apt-get install -y software-properties-common \".  Please wait...\n",
            "OK.\n",
            "Running command: \"sudo add-apt-repository -y ppa:ubuntugis/ppa && apt-get -y update\".  Please wait...\n",
            "OK.\n",
            "Running command: \"sudo apt-get install -y libspatialindex-dev python-rtree gdal-bin\".  Please wait...\n",
            "OK.\n",
            "Running command: \"sudo apt-get install -y build-essential libssl-dev libffi-dev libxml2-dev libxslt1-dev zlib1g-dev\".  Please wait...\n",
            "OK.\n",
            "Running command: \"sudo apt-get install -y libgdal-dev \".  Please wait...\n",
            "OK.\n",
            "Running command: \"sudo gdal-config --version \".  Please wait...\n",
            "OK.\n",
            "Running command: \"pip install affine>=2.3.0 \".  Please wait...\n",
            "OK.\n",
            "Running command: \"pip install albumentations==0.4.3\".  Please wait...\n",
            "OK.\n",
            "Running command: \"pip install fiona>=1.7.13 \".  Please wait...\n",
            "OK.\n",
            "Running command: \"pip install geopandas>=0.7.0\".  Please wait...\n",
            "OK.\n",
            "Running command: \"pip install matplotlib>=3.1.2\".  Please wait...\n",
            "OK.\n",
            "Running command: \"pip install networkx>=2.4 \".  Please wait...\n",
            "OK.\n",
            "Running command: \"pip install opencv-python>=4.1\".  Please wait...\n",
            "OK.\n",
            "Running command: \"pip install pandas>=0.25.3 \".  Please wait...\n",
            "OK.\n",
            "Running command: \"pip install pyproj>=2.1 \".  Please wait...\n",
            "OK.\n",
            "Running command: \"pip install pyyaml==5.2\".  Please wait...\n",
            "OK.\n",
            "Running command: \"pip install rasterio>=1.0.23\".  Please wait...\n",
            "OK.\n",
            "Running command: \"pip install requests==2.22.0\".  Please wait...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "idna",
                  "requests"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "OK.\n",
            "Running command: \"pip install rtree>=0.9.3 \".  Please wait...\n",
            "OK.\n",
            "Running command: \"pip install scikit-image>=0.16.2\".  Please wait...\n",
            "OK.\n",
            "Running command: \"pip install scipy>=1.3.2 \".  Please wait...\n",
            "OK.\n",
            "Running command: \"pip install torchvision>=0.5.0\".  Please wait...\n",
            "OK.\n",
            "Running command: \"pip install tqdm>=4.40.0 \".  Please wait...\n",
            "OK.\n",
            "Running command: \"pip install urllib3>=1.25.7\".  Please wait...\n",
            "OK.\n",
            "Running command: \"pip install gdal>=3.0.2 \".  Please wait...\n",
            "OK.\n",
            "Running command: \"pip install tensorflow-gpu==1.13.1\".  Please wait...\n",
            "OK.\n",
            "CMDS ['cd /content/spacenet6challenge/solaris && pip install .'] False\n",
            "Running command: \"cd /content/spacenet6challenge/solaris && pip install .\".  Please wait...\n",
            "\n",
            "All baseline prereqs have been installed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QplMAtPq7FnK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Useful for print debugging solaris\n",
        "if reinstall_solaris:\n",
        "  !pip uninstall solaris\n",
        "  !cd /content/spacenet6challenge/solaris && python setup.py clean\n",
        "  !cd /content/spacenet6challenge/solaris && pip install .\n",
        "  import solaris\n",
        "  import importlib\n",
        "  importlib.reload(solaris)\n",
        "  solaris_ok = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Y6XgdnI_bgE",
        "colab_type": "code",
        "outputId": "76a8c1f0-96e6-4f35-9c29-7b10039703e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# TODO:  Why do we need to do this here...\n",
        "if not solaris_ok:\n",
        "  !pip install shapely\n",
        "  !cd /content/spacenet6challenge/solaris && python setup.py clean\n",
        "  !cd /content/spacenet6challenge/solaris && pip install .\n",
        "  try:\n",
        "    #from solaris import utils\n",
        "    #print(\"Found solaris package.  Assuming installation worked.\")\n",
        "    solaris_ok = True\n",
        "  except:\n",
        "    raise Exception(\"You should restart the kernel and run the notebook again.\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: shapely in /usr/local/lib/python3.6/dist-packages (1.7.0)\n",
            "Collecting git+git://github.com/toblerity/shapely@master\n",
            "  Cloning git://github.com/toblerity/shapely (to revision master) to /tmp/pip-req-build-a5r6h131\n",
            "  Running command git clone -q git://github.com/toblerity/shapely /tmp/pip-req-build-a5r6h131\n",
            "Building wheels for collected packages: Shapely\n",
            "  Building wheel for Shapely (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Shapely: filename=Shapely-1.8.dev0-cp36-cp36m-linux_x86_64.whl size=664959 sha256=5641540278c4f4ee1ac6eae9b6b67352e51bc8e241852230a0fb1fe3c7a0e8ea\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-cgjncjbn/wheels/b5/64/12/74e189eed9f8e46360196a89a3c2572059194e4f48b2daca95\n",
            "Successfully built Shapely\n",
            "Installing collected packages: Shapely\n",
            "  Found existing installation: Shapely 1.7.0\n",
            "    Uninstalling Shapely-1.7.0:\n",
            "      Successfully uninstalled Shapely-1.7.0\n",
            "Successfully installed Shapely-1.8.dev0\n",
            "running clean\n",
            "Processing /content/spacenet6challenge/solaris\n",
            "Requirement already satisfied: pip>=19.0.3 in /usr/local/lib/python3.6/dist-packages (from solaris==0.2.2) (19.3.1)\n",
            "Requirement already satisfied: affine>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from solaris==0.2.2) (2.3.0)\n",
            "Requirement already satisfied: albumentations==0.4.3 in /usr/local/lib/python3.6/dist-packages (from solaris==0.2.2) (0.4.3)\n",
            "Requirement already satisfied: fiona>=1.7.13 in /usr/local/lib/python3.6/dist-packages (from solaris==0.2.2) (1.8.13.post1)\n",
            "Requirement already satisfied: geopandas>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from solaris==0.2.2) (0.7.0)\n",
            "Requirement already satisfied: matplotlib>=3.1.2 in /usr/local/lib/python3.6/dist-packages (from solaris==0.2.2) (3.2.1)\n",
            "Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.6/dist-packages (from solaris==0.2.2) (2.4)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.6/dist-packages (from solaris==0.2.2) (1.18.3)\n",
            "Requirement already satisfied: opencv-python>=4.1 in /usr/local/lib/python3.6/dist-packages (from solaris==0.2.2) (4.1.2.30)\n",
            "Requirement already satisfied: pandas>=0.25.3 in /usr/local/lib/python3.6/dist-packages (from solaris==0.2.2) (1.0.3)\n",
            "Requirement already satisfied: pyproj>=2.1 in /usr/local/lib/python3.6/dist-packages (from solaris==0.2.2) (2.6.1.post1)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.6/dist-packages (from solaris==0.2.2) (1.5.0+cu101)\n",
            "Requirement already satisfied: pyyaml==5.2 in /usr/local/lib/python3.6/dist-packages (from solaris==0.2.2) (5.2)\n",
            "Requirement already satisfied: rasterio>=1.0.23 in /usr/local/lib/python3.6/dist-packages (from solaris==0.2.2) (1.1.3)\n",
            "Requirement already satisfied: requests==2.22.0 in /usr/local/lib/python3.6/dist-packages (from solaris==0.2.2) (2.22.0)\n",
            "Requirement already satisfied: rtree>=0.9.3 in /usr/local/lib/python3.6/dist-packages (from solaris==0.2.2) (0.9.4)\n",
            "Requirement already satisfied: scikit-image>=0.16.2 in /usr/local/lib/python3.6/dist-packages (from solaris==0.2.2) (0.16.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.6/dist-packages (from solaris==0.2.2) (1.4.1)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from solaris==0.2.2) (0.6.0+cu101)\n",
            "Collecting tqdm>=4.40.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/40/058b12e8ba10e35f89c9b1fdfc2d4c7f8c05947df2d5eb3c7b258019fda0/tqdm-4.46.0-py2.py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 2.5MB/s \n",
            "\u001b[?25hCollecting urllib3>=1.25.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/e5/df302e8017440f111c11cc41a6b432838672f5a70aa29227bf58149dc72f/urllib3-1.25.9-py2.py3-none-any.whl (126kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 9.7MB/s \n",
            "\u001b[?25hCollecting tensorflow==1.13.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/63/a9fa76de8dffe7455304c4ed635be4aa9c0bacef6e0633d87d5f54530c5c/tensorflow-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (92.5MB)\n",
            "\u001b[K     |████████████████████████████████| 92.5MB 33kB/s \n",
            "\u001b[?25hRequirement already satisfied: imgaug<0.2.7,>=0.2.5 in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.3->solaris==0.2.2) (0.2.6)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.6/dist-packages (from fiona>=1.7.13->solaris==0.2.2) (2.5.0)\n",
            "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.6/dist-packages (from fiona>=1.7.13->solaris==0.2.2) (1.12.0)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.6/dist-packages (from fiona>=1.7.13->solaris==0.2.2) (0.5.0)\n",
            "Requirement already satisfied: click<8,>=4.0 in /usr/local/lib/python3.6/dist-packages (from fiona>=1.7.13->solaris==0.2.2) (7.1.2)\n",
            "Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.6/dist-packages (from fiona>=1.7.13->solaris==0.2.2) (19.3.0)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.6/dist-packages (from fiona>=1.7.13->solaris==0.2.2) (1.1.1)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.6/dist-packages (from geopandas>=0.7.0->solaris==0.2.2) (1.8.dev0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.1.2->solaris==0.2.2) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.1.2->solaris==0.2.2) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.1.2->solaris==0.2.2) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.1.2->solaris==0.2.2) (2.4.7)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.4->solaris==0.2.2) (4.4.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.25.3->solaris==0.2.2) (2018.9)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.1->solaris==0.2.2) (0.16.0)\n",
            "Requirement already satisfied: snuggs>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from rasterio>=1.0.23->solaris==0.2.2) (1.4.7)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->solaris==0.2.2) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->solaris==0.2.2) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->solaris==0.2.2) (2020.4.5.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from rtree>=0.9.3->solaris==0.2.2) (46.1.3)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16.2->solaris==0.2.2) (2.4.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16.2->solaris==0.2.2) (7.0.0)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16.2->solaris==0.2.2) (1.1.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->solaris==0.2.2) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->solaris==0.2.2) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->solaris==0.2.2) (0.3.3)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->solaris==0.2.2) (1.0.8)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->solaris==0.2.2) (3.10.0)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->solaris==0.2.2) (1.13.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->solaris==0.2.2) (0.34.2)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->solaris==0.2.2) (1.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->solaris==0.2.2) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->solaris==0.2.2) (1.28.1)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1->solaris==0.2.2) (0.9.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.1->solaris==0.2.2) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1->solaris==0.2.2) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1->solaris==0.2.2) (1.0.1)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow==1.13.1->solaris==0.2.2) (4.0.2)\n",
            "Building wheels for collected packages: solaris\n",
            "  Building wheel for solaris (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for solaris: filename=solaris-0.2.2-cp36-none-any.whl size=14909551 sha256=082fda135808e56b44cb64cebee88a2a4c3f5e666697e10d8496b98bb8832fc0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-art87aap/wheels/04/a2/75/2a2d5df881c7731dd6ec79cd6b342e5db6a337348c4a5a98c0\n",
            "Successfully built solaris\n",
            "\u001b[31mERROR: kaggle 1.5.6 has requirement urllib3<1.25,>=1.21.1, but you'll have urllib3 1.25.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tqdm, urllib3, tensorflow, solaris\n",
            "  Found existing installation: tqdm 4.38.0\n",
            "    Uninstalling tqdm-4.38.0:\n",
            "      Successfully uninstalled tqdm-4.38.0\n",
            "  Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Found existing installation: tensorflow 2.2.0rc4\n",
            "    Uninstalling tensorflow-2.2.0rc4:\n",
            "      Successfully uninstalled tensorflow-2.2.0rc4\n",
            "Successfully installed solaris-0.2.2 tensorflow-1.13.1 tqdm-4.46.0 urllib3-1.25.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acUsiBeJMwJ6",
        "colab_type": "code",
        "outputId": "ff726262-d7d5-4f79-c1b2-92e5a225f5ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "import solaris\n",
        "import importlib\n",
        "importlib.reload(solaris)\n",
        "import solaris\n",
        "dir(solaris)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__builtins__',\n",
              " '__cached__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__path__',\n",
              " '__spec__',\n",
              " '__version__',\n",
              " 'bin',\n",
              " 'data',\n",
              " 'eval',\n",
              " 'nets',\n",
              " 'raster',\n",
              " 'tile',\n",
              " 'utils',\n",
              " 'vector']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUe1vQuqywVo",
        "colab_type": "code",
        "outputId": "255c4037-ccd3-4067-d686-9b333f591753",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Check tensorflow \n",
        "import tensorflow\n",
        "print(\"tensorflow version=\",tensorflow.version.VERSION)\n",
        "if (tensorflow.version.VERSION!='1.13.1'):\n",
        "  raise Exception(\"You need to restart the kernel and resume from here.\")\n",
        "\n",
        "# Check torch \n",
        "import torch\n",
        "print( \"torch version=\", torch.version.__version__) \n",
        "if not torch.version.__version__.startswith(\"1.5\"):\n",
        "  raise Exception(\"You need restart the kernel and resume from here.\")\n",
        "if not torch.cuda.is_available():\n",
        "  raise Exception(\"Torch cuda is not available.\")\n",
        "else:\n",
        "  print(\"Torch cuda is available.\")\n",
        "\n",
        "# Check all installation packages are available\n",
        "try:\n",
        "  import solaris\n",
        "  from solaris import utils\n",
        "  import sys\n",
        "  !pip install geopandas>=0.7.0\n",
        "  import geopandas\n",
        "  sys.path.append('/content/spacenet6challenge/CosmiQ_SN6_Baseline')\n",
        "  import baseline\n",
        "  sys.path.append('/content/spacenet6challenge')\n",
        "  from spacenet6.cosmiq import baseline_wrap\n",
        "except:\n",
        "  raise Exception(\"Installation checks failed.\")\n",
        "\n",
        "print(\"Installation checks passed.\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensorflow version= 1.13.1\n",
            "torch version= 1.5.0+cu101\n",
            "Torch cuda is available.\n",
            "Installation checks passed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwEv9uuDDAVE",
        "colab_type": "code",
        "outputId": "9cafa178-03ed-475b-e378-4d45b7e6eaa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "# Mount GCP bucket data\n",
        "import sys\n",
        "sys.path.append('./spacenet6challenge')\n",
        "import spacenet6.colab.bucket\n",
        "spacenet6.colab.bucket.mount(\"spacenet_challenge_data\",force_new_mount=True)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking for jupyter/ipython environment...\n",
            "Passed.\n",
            "Checking for colab environment...\n",
            "Passed.\n",
            "Trying to authenticate GCP user...\n",
            "Running command: \"echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\".  Please wait...\n",
            "OK.\n",
            "Running command: \"curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add - \".  Please wait...\n",
            "OK.\n",
            "Running command: \"apt -qq update\".  Please wait...\n",
            "OK.\n",
            "Running command: \"apt -qq install gcsfuse\".  Please wait...\n",
            "OK.\n",
            "Running command: \"mkdir mountOnColab\".  Please wait...\n",
            "OK.\n",
            "Running command: \"gcsfuse --implicit-dirs spacenet_challenge_data mountOnColab\".  Please wait...\n",
            "OK.\n",
            "Done. Getting folder contents...\n",
            "Running command: \"ls -als /content/mountOnColab\".  Please wait...\n",
            "\n",
            "Mount was successful.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onKAnaXCJpm0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "# Do some config checks\n",
        "#\n",
        "import os\n",
        "\n",
        "# pretrain path\n",
        "if not os.path.exists(pretrain_path):\n",
        "  raise Exception(\"pretrain path does not exist.\")\n",
        "\n",
        "# train sessions toplevel\n",
        "if not os.path.exists(train_sessions_path):\n",
        "  raise Exception(\"train sessions path does not exist.\")\n",
        "\n",
        "# configs dir for yaml templates and csv's\n",
        "if not os.path.exists(configs_path):\n",
        "  raise Exception(\"configs path does not exist.\")\n",
        "\n",
        "# Dated training sessions directory containing weights\n",
        "if not os.path.exists( os.path.join( train_sessions_path, session_date, \"weights\" ) ):\n",
        "  raise Exception(\"No session dir %s with weights\" % session_date )\n",
        "\n",
        "# Name of weights file\n",
        "weights_path = os.path.join( train_sessions_path, session_date, \"weights\", weights_file_name )\n",
        "if not os.path.exists( weights_path ):\n",
        "  raise Exception(\"Invalid weights path-> %s\" % weights_path )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiSxhdrg331e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "fa93cd52-5344-4d1d-e89e-6a5ccfe0f608"
      },
      "source": [
        "# Eval on SAR model\n",
        "import os\n",
        "import datetime\n",
        "import solaris as sol\n",
        "import model\n",
        "\n",
        "# create a dir for this test session\n",
        "dpath = str(datetime.datetime.now()).replace(\":\",\"_\").replace(\" \",\"_\")\n",
        "outpath = '%s/%s/%s' % ( train_sessions_path, \"test_sessions\", dpath )\n",
        "os.makedirs(outpath,exist_ok=True)\n",
        "\n",
        "# create test.csv from template\n",
        "f = open( os.path.join(configs_path,'test.csv') )\n",
        "txt = f.read()\n",
        "f.close()\n",
        "newtxt = txt.replace('./root',pretrain_path)\n",
        "traincsv = os.path.join( outpath, \"test.csv\")\n",
        "f = open(testcsv, 'w')\n",
        "f.write(newtxt)\n",
        "f.flush()\n",
        "f.close()\n",
        "\n",
        "# create an eval yaml from template\n",
        "f = open( os.path.join(configs_path, 'eval_sar.yaml') )\n",
        "txt = f.read()\n",
        "f.close()\n",
        "newtxt = txt.replace(\"DATEDIR\",outpath)\n",
        "newtxt = newtxt.replace(\"TESTCSV\",testcsv)\n",
        "newyaml = os.path.join( outpath, \"eval_sar.yaml\")\n",
        "f = open(newyaml,'w')\n",
        "f.write(newtxt)\n",
        "f.flush()\n",
        "f.close()\n",
        "\n",
        "print(\"Wrote file->%s\" % newyaml)\n",
        "\n",
        "# create a test config from yaml\n",
        "config = sol.utils.config.parse(newyaml)\n",
        "config['pretrained'] = False\n",
        "\n",
        "sar_dict = {\n",
        "    'model_name': 'unet11',\n",
        "    'weight_path': None,\n",
        "    'weight_url': None,\n",
        "    'arch': model.UNet11\n",
        "}\n",
        "\n",
        "# test\n",
        "#trainer = sol.nets.train.Trainer(config, custom_model_dict=sar_dict)\n",
        "#trainer.train()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-98df99e28b05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# create test.csv from template\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfigs_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'test.csv'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mtxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './spacenet6challenge/configs/test.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u01ekuPLoMgh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate on test data\n",
        "\n",
        "if False:\n",
        "\n",
        "  #model output directory= /content/mountOnColab/train_sessions/2020-05-03_14_04_02.011290\n",
        "  #model weights directory= /content/mountOnColab/train_sessions/2020-05-03_14_04_02.011290/weights\n",
        "\n",
        "  # Verify all the directories\n",
        "  import os\n",
        "  import datetime\n",
        "  import importlib\n",
        "  import sys\n",
        "  sys.path.append('./spacenet6challenge/CosmiQ_SN6_Baseline')\n",
        "  sys.path.append('./spacenet6challenge/')\n",
        "  from spacenet6.cosmiq import baseline_wrap\n",
        "  import baseline\n",
        "  importlib.reload(baseline)\n",
        "  import importlib\n",
        "  importlib.reload(baseline_wrap)\n",
        "\n",
        "  # where is the raw test SAR data?\n",
        "  test_path = \"/content/mountOnColab/SAR/test_public/AOI_11_Rotterdam\"\n",
        "  if not os.path.exists(test_path):\n",
        "    raise Exception(\"Could not find training data\")\n",
        "\n",
        "  # where is the pretrain_pretest data?\n",
        "  pretrain_pretest_path = '/content/mountOnColab/pretrain'\n",
        "  if not os.path.exists(pretrain_pretest_path):\n",
        "    raise Exception('Could not find pretrain data')\n",
        "\n",
        "  # validate the directory where we load the weights.\n",
        "  if not os.path.exists( os.path.join(read_model_weights_toplevel_dir, \"weights\" ) ):\n",
        "    raise Exception(\"model weights dir does not exist.\")\n",
        "\n",
        "  # where to put output from this test eval session?\n",
        "  test_sessions_path = '/content/mountOnColab/tests_sessions'\n",
        "  dpath = str(datetime.datetime.now()).replace(\":\",\"_\").replace(\" \",\"_\")\n",
        "  outpath = '%s/%s' % ( test_sessions_path, dpath )\n",
        "  os.makedirs( os.path.join( outpath, \"sartest\"), exist_ok=True )\n",
        "  os.makedirs( os.path.join( outpath, \"inference_continuous\"), exist_ok=True )\n",
        "  os.makedirs( os.path.join( outpath, \"inference_binary\"), exist_ok=True )\n",
        "  os.makedirs( os.path.join( outpath, \"inference_vectors\"), exist_ok=True )\n",
        "\n",
        "  cmdargs = [ \"--test\",\n",
        "                  \"--testdir\", \"%s/SAR-Intensity\" % test_path,\n",
        "                              \"--rotationfilelocal\",\"%s/SAR_orientations.txt\" % pretrain_pretest_path,\n",
        "                              \"--maskdir\", \"%s/masks\" % pretrain_pretest_path,\n",
        "                              \"--sarprocdir\", \"%s/sartrain\" % pretrain_pretest_path, \n",
        "                              \"--opticalprocdir\",\"%s/optical\" % pretrain_pretest_path,\n",
        "                              \"--testcsv\",\"%s/test.csv\" % pretrain_pretest_path,\n",
        "                              \"--yamlpath\",\"%s/infer.yaml\" % pretrain_pretest_path,\n",
        "                              \"--modeldir\",\"%s/weights\" % read_model_weights_toplevel_dir,\n",
        "                              \"--testprocdir\",\"%s/sartest\" % outpath,\n",
        "                              \"--testoutdir\",\"%s/inference_continuous\" % outpath,\n",
        "                              \"--testbinarydir\",\"%s/inference_binary\" % outpath,\n",
        "                              \"--testvectordir\",\"%s/inference_vectors\" % outpath,\n",
        "                              \"--rotate\",\n",
        "                              \"--mintestsize\",\"80\"]\n",
        "  args = baseline_wrap.parse_args(cmdargs)\n",
        "  #print(args)\n",
        "  #import importlib\n",
        "  #importlib.reload(baseline_wrap)\n",
        "  print(vars(args))\n",
        "  baseline_wrap.invoke(outpath, \"/content/mountOnColab/pretrain\", args)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gwilliams/Projects/FractalsProject/spacenet6challenge/notebooks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gwilliams/opt/miniconda_for_spacenet6_local_jupyter/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/gwilliams/opt/miniconda_for_spacenet6_local_jupyter/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/gwilliams/opt/miniconda_for_spacenet6_local_jupyter/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/gwilliams/opt/miniconda_for_spacenet6_local_jupyter/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/gwilliams/opt/miniconda_for_spacenet6_local_jupyter/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/gwilliams/opt/miniconda_for_spacenet6_local_jupyter/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded all packages.\n"
     ]
    }
   ],
   "source": [
    "# Make sure we can load all the packages\n",
    "try:\n",
    "    import sys\n",
    "    import os\n",
    "    print(os.getcwd())\n",
    "    import solaris\n",
    "    sys.path.append(\"../CosmiQ_SN6_Baseline/\")\n",
    "    import baseline\n",
    "    sys.path.append(\"../\")\n",
    "    import spacenet6\n",
    "    from spacenet6.cosmiq import baseline_wrap\n",
    "    print(\"Loaded all packages.\")\n",
    "except:\n",
    "    raise Exception(\"Problem loading packages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote file->../../data/spacenet6/train_sessions/2020-05-05_11_32_41.373366/train_sar.yaml\n",
      "Beginning training epoch 0\n",
      "Train Pytorch CUDA NOTAVAIL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/distiller/project/conda/conda-bld/pytorch_1587428061935/work/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    loss at batch 0: 3.376142978668213\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 10: 2.023456573486328\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 20: 1.625366449356079\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 30: 1.136474847793579\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n"
     ]
    }
   ],
   "source": [
    "# Train on SAR only\n",
    "import os\n",
    "import datetime\n",
    "import solaris as sol\n",
    "import model\n",
    "\n",
    "\n",
    "# validate sessios toplevel\n",
    "train_sessions_path = '../../data/spacenet6/train_sessions'\n",
    "if not os.path.exists(train_sessions_path):\n",
    "  raise Exception(\"train sessions path does not exist.\")\n",
    "\n",
    "# create a dir for this training session\n",
    "dpath = str(datetime.datetime.now()).replace(\":\",\"_\").replace(\" \",\"_\")\n",
    "outpath = '%s/%s' % ( train_sessions_path, dpath )\n",
    "os.makedirs(outpath,exist_ok=True)\n",
    "weightpath = os.path.join(outpath, \"weights\")\n",
    "os.makedirs(outpath,exist_ok=True)\n",
    "\n",
    "# create train.csv from template\n",
    "f = open('../configs/train.csv')\n",
    "txt = f.read()\n",
    "f.close()\n",
    "newtxt = txt.replace('./root','../../data/spacenet6/pretrain')\n",
    "traincsv = os.path.join( outpath, \"train.csv\")\n",
    "f = open(traincsv, 'w')\n",
    "f.write(newtxt)\n",
    "f.flush()\n",
    "f.close()\n",
    "\n",
    "# create valid.csv from template\n",
    "f = open('../configs/valid.csv')\n",
    "txt = f.read()\n",
    "f.close()\n",
    "newtxt = txt.replace('./root','../../data/spacenet6/pretrain')\n",
    "validcsv = os.path.join( outpath, \"valid.csv\")\n",
    "f = open(validcsv, 'w')\n",
    "f.write(newtxt)\n",
    "f.flush()\n",
    "f.close()\n",
    "\n",
    "# create a SAR training yaml from template\n",
    "f = open('../configs/train_sar.yaml')\n",
    "txt = f.read()\n",
    "f.close()\n",
    "newtxt = txt.replace(\"DATEDIR\",outpath)\n",
    "newtxt = newtxt.replace(\"TRAINCSV\",traincsv)\n",
    "newtxt = newtxt.replace(\"VALIDCSV\",validcsv)\n",
    "newyaml = os.path.join( outpath, \"train_sar.yaml\")\n",
    "f = open(newyaml,'w')\n",
    "f.write(newtxt)\n",
    "f.flush()\n",
    "f.close()\n",
    "\n",
    "print(\"Wrote file->%s\" % newyaml)\n",
    "\n",
    "# create a training config from yaml\n",
    "config = sol.utils.config.parse(newyaml)\n",
    "config['pretrained'] = False\n",
    "\n",
    "sar_dict = {\n",
    "    'model_name': 'unet11',\n",
    "    'weight_path': None,\n",
    "    'weight_url': None,\n",
    "    'arch': model.UNet11\n",
    "}\n",
    "\n",
    "# train\n",
    "trainer = sol.nets.train.Trainer(config, custom_model_dict=sar_dict)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model directory= ../../data/spacenet6/train_sessions/2020-05-03_10_40_14.989557\n",
      "model weights directory= ../../data/spacenet6/train_sessions/2020-05-03_10_40_14.989557/weights\n"
     ]
    }
   ],
   "source": [
    "\n",
    "resume = False\n",
    "\n",
    "# Verify all the directories\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "train_path = \"../../data/spacenet6/train/AOI_11_Rotterdam\"\n",
    "if not os.path.exists(train_path):\n",
    "  raise Exception(\"Could not find training data\")\n",
    "\n",
    "pretrain_path = '../../data/spacenet6/pretrain'\n",
    "if not os.path.exists(pretrain_path):\n",
    "  raise Exception('Could not find pretrain data')\n",
    "\n",
    "train_sessions_path = '../../data/spacenet6/train_sessions'\n",
    "\n",
    "# are we trying to resume a training session \n",
    "if resume: \n",
    "\n",
    "  # Get the last trained model and figure out where to resume...\n",
    "  print(\"Will try to resume training from trainining=>\", resume)\n",
    "  dpath = resume\n",
    "  outpath = '%s/%s' % ( train_sessions_path, dpath )\n",
    "  if not os.path.exists( outpath ):\n",
    "    raise Exception(\"Can't resume because %s does not exist.\" % outpath)\n",
    "  subdirs = os.listdir( os.path.join(outpath, \"weights\"))\n",
    "  print(\"listdir=\", subdirs)\n",
    "  epochs = sorted( [ int( subdir.split(\".\")[0] ) for subdir in subdirs if subdir.split(\".\")[0].isnumeric() ] )\n",
    "  print(\"all epochs=\", epochs)\n",
    "  resume_epoch = int(epochs[-1])\n",
    "  resume_weights = os.path.join(outpath,\"weights/%d.hdf5\" % resume_epoch )\n",
    "  raise Exception(\"Not finished.\")\n",
    "else:\n",
    "\n",
    "  # Create new dated directory for saved weights...\n",
    "  resume_epoch = None\n",
    "  resume_weights = None\n",
    "  dpath = str(datetime.datetime.now()).replace(\":\",\"_\").replace(\" \",\"_\")\n",
    "  outpath = '%s/%s' % ( train_sessions_path, dpath )\n",
    "\n",
    "os.makedirs(outpath, exist_ok=True)\n",
    "print(\"model directory=\", outpath)\n",
    "\n",
    "weights_dir = os.path.join( outpath, \"weights\")\n",
    "os.makedirs(weights_dir, exist_ok=True)\n",
    "print(\"model weights directory=\", weights_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For arg 'pretrain', checking if 'False' is a path...\n",
      "For arg 'train', checking if 'True' is a path...\n",
      "For arg 'pretest', checking if 'False' is a path...\n",
      "For arg 'test', checking if 'False' is a path...\n",
      "For arg 'eval', checking if 'False' is a path...\n",
      "For arg 'sardir', checking if '../../data/spacenet6/train/AOI_11_Rotterdam/SAR-Intensity' is a path...\n",
      "For arg 'opticaldir', checking if '../../data/spacenet6/train/AOI_11_Rotterdam/PS-RGB' is a path...\n",
      "For arg 'labeldir', checking if '../../data/spacenet6/train/AOI_11_Rotterdam/geojson_buildings' is a path...\n",
      "For arg 'rotationfile', checking if '../../data/spacenet6/train/AOI_11_Rotterdam/SummaryData/SAR_orientations.txt' is a path...\n",
      "Found file ../../data/spacenet6/train/AOI_11_Rotterdam/SummaryData/SAR_orientations.txt\n",
      "For arg 'rotationfilelocal', checking if '../../data/spacenet6/pretrain/SAR_orientations.txt' is a path...\n",
      "Found file ../../data/spacenet6/pretrain/SAR_orientations.txt\n",
      "For arg 'maskdir', checking if '../../data/spacenet6/pretrain/masks' is a path...\n",
      "For arg 'sarprocdir', checking if '../../data/spacenet6/pretrain/sartrain' is a path...\n",
      "For arg 'opticalprocdir', checking if '../../data/spacenet6/pretrain/optical' is a path...\n",
      "For arg 'traincsv', checking if '../../data/spacenet6/pretrain/train.csv' is a path...\n",
      "Found file ../../data/spacenet6/pretrain/train.csv\n",
      "Copying file to ../../data/spacenet6/train_sessions/2020-05-03_10_40_14.989557/train.csv and fixing paths\n",
      "For arg 'validcsv', checking if '../../data/spacenet6/pretrain/valid.csv' is a path...\n",
      "Found file ../../data/spacenet6/pretrain/valid.csv\n",
      "Copying file to ../../data/spacenet6/train_sessions/2020-05-03_10_40_14.989557/valid.csv and fixing paths\n",
      "For arg 'opticaltraincsv', checking if '../../data/spacenet6/pretrain/opticaltrain.csv' is a path...\n",
      "Found file ../../data/spacenet6/pretrain/opticaltrain.csv\n",
      "Copying file to ../../data/spacenet6/train_sessions/2020-05-03_10_40_14.989557/opticaltrain.csv and fixing paths\n",
      "For arg 'opticalvalidcsv', checking if '../../data/spacenet6/pretrain/opticalvalid.csv' is a path...\n",
      "Found file ../../data/spacenet6/pretrain/opticalvalid.csv\n",
      "Copying file to ../../data/spacenet6/train_sessions/2020-05-03_10_40_14.989557/opticalvalid.csv and fixing paths\n",
      "For arg 'testcsv', checking if '../../data/spacenet6/pretrain/test.csv' is a path...\n",
      "For arg 'yamlpath', checking if '../../data/spacenet6/train_sessions/2020-05-03_10_40_14.989557/sar.yaml' is a path...\n",
      "For arg 'opticalyamlpath', checking if '../../data/spacenet6/train_sessions/2020-05-03_10_40_14.989557/optical.yaml' is a path...\n",
      "For arg 'modeldir', checking if '../../data/spacenet6/train_sessions/2020-05-03_10_40_14.989557/weights' is a path...\n",
      "For arg 'testdir', checking if 'None' is a path...\n",
      "For arg 'testprocdir', checking if '../../data/spacenet6/train_sessions/2020-05-03_10_40_14.989557/sartest' is a path...\n",
      "For arg 'testoutdir', checking if '../../data/spacenet6/train_sessions/2020-05-03_10_40_14.989557/inference_continuous' is a path...\n",
      "For arg 'testbinarydir', checking if '../../data/spacenet6/train_sessions/2020-05-03_10_40_14.989557/inference_binary' is a path...\n",
      "For arg 'testvectordir', checking if '../../data/spacenet6/train_sessions/2020-05-03_10_40_14.989557/inference_vectors' is a path...\n",
      "For arg 'outputcsv', checking if 'None' is a path...\n",
      "For arg 'rotate', checking if 'True' is a path...\n",
      "For arg 'transferoptical', checking if 'True' is a path...\n",
      "For arg 'mintrainsize', checking if '20' is a path...\n",
      "For arg 'mintestsize', checking if '80' is a path...\n",
      "For arg 'uselastmodel', checking if 'False' is a path...\n",
      "For arg 'earlycutoff', checking if 'None' is a path...\n",
      "Fixup done:\n",
      "{'pretrain': False, 'train': True, 'pretest': False, 'test': False, 'eval': False, 'sardir': '../../data/spacenet6/train/AOI_11_Rotterdam/SAR-Intensity', 'opticaldir': '../../data/spacenet6/train/AOI_11_Rotterdam/PS-RGB', 'labeldir': '../../data/spacenet6/train/AOI_11_Rotterdam/geojson_buildings', 'rotationfile': '../../data/spacenet6/train/AOI_11_Rotterdam/SummaryData/SAR_orientations.txt', 'rotationfilelocal': '../../data/spacenet6/pretrain/SAR_orientations.txt', 'maskdir': '../../data/spacenet6/pretrain/masks', 'sarprocdir': '../../data/spacenet6/pretrain/sartrain', 'opticalprocdir': '../../data/spacenet6/pretrain/optical', 'traincsv': '../../data/spacenet6/train_sessions/2020-05-03_10_40_14.989557/train.csv', 'validcsv': '../../data/spacenet6/train_sessions/2020-05-03_10_40_14.989557/valid.csv', 'opticaltraincsv': '../../data/spacenet6/train_sessions/2020-05-03_10_40_14.989557/opticaltrain.csv', 'opticalvalidcsv': '../../data/spacenet6/train_sessions/2020-05-03_10_40_14.989557/opticalvalid.csv', 'testcsv': '../../data/spacenet6/pretrain/test.csv', 'yamlpath': '../../data/spacenet6/train_sessions/2020-05-03_10_40_14.989557/sar.yaml', 'opticalyamlpath': '../../data/spacenet6/train_sessions/2020-05-03_10_40_14.989557/optical.yaml', 'modeldir': '../../data/spacenet6/train_sessions/2020-05-03_10_40_14.989557/weights', 'testdir': None, 'testprocdir': '../../data/spacenet6/train_sessions/2020-05-03_10_40_14.989557/sartest', 'testoutdir': '../../data/spacenet6/train_sessions/2020-05-03_10_40_14.989557/inference_continuous', 'testbinarydir': '../../data/spacenet6/train_sessions/2020-05-03_10_40_14.989557/inference_binary', 'testvectordir': '../../data/spacenet6/train_sessions/2020-05-03_10_40_14.989557/inference_vectors', 'outputcsv': None, 'rotate': True, 'transferoptical': True, 'mintrainsize': '20', 'mintestsize': '80', 'uselastmodel': False, 'earlycutoff': None}\n",
      "Train\n",
      "Training on Optical: Start\n",
      "Beginning training epoch 0\n",
      "Train Pytorch CUDA NOTAVAIL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/distiller/project/conda/conda-bld/pytorch_1587428061935/work/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    loss at batch 0: 2.5635058879852295\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 10: 1.8316764831542969\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 20: 1.2072319984436035\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 30: 1.0374197959899902\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 40: 0.9786252975463867\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 50: 1.0418131351470947\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 60: 1.1150352954864502\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 70: 0.9434170722961426\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 80: 0.9534217715263367\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 90: 1.0371201038360596\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 100: 0.9260808229446411\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 110: 1.0454881191253662\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 120: 1.0192512273788452\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 130: 0.9425826668739319\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 140: 0.9215091466903687\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 150: 0.9148224592208862\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 160: 0.8961613774299622\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 170: 0.8563345670700073\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 180: 0.8409678936004639\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 190: 0.9432310461997986\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 200: 0.9464906454086304\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 210: 0.981734037399292\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 220: 0.9685948491096497\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 230: 0.8382242918014526\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 240: 0.8260201811790466\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 250: 0.9443148374557495\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 260: 0.9215424060821533\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 270: 0.827375590801239\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 280: 0.8479402661323547\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 290: 0.925148606300354\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 300: 0.8546638488769531\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 310: 0.8999718427658081\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 320: 0.7964733839035034\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 330: 0.8940620422363281\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "\n",
      "    Validation loss at epoch 0: 0.7627224922180176\n",
      "\n",
      "Beginning training epoch 1\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 0: 0.8943203687667847\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 10: 0.8013303279876709\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 20: 0.884196400642395\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 30: 0.7103946805000305\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 40: 0.7392189502716064\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 50: 0.8488941192626953\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 60: 0.8369496464729309\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 70: 0.7422424554824829\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 80: 0.7879121899604797\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 90: 0.8314411640167236\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 100: 0.7437125444412231\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 110: 0.9207529425621033\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 120: 0.6436288356781006\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 130: 0.7682915925979614\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 140: 0.6357603073120117\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 150: 0.9349220991134644\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 160: 0.6539753079414368\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 170: 0.8027739524841309\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 180: 0.8046990633010864\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 190: 0.8574609756469727\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 200: 0.5917336940765381\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 210: 0.734083354473114\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 220: 0.8114541172981262\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 230: 0.6492923498153687\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 240: 0.7224710583686829\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 250: 0.6045386791229248\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 260: 0.7921162843704224\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 270: 0.7414876222610474\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 280: 0.6917784810066223\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 290: 0.659686803817749\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 300: 0.6830064058303833\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 310: 0.6012793779373169\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 320: 0.65726637840271\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 330: 0.6131622791290283\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "\n",
      "    Validation loss at epoch 1: 0.6034783124923706\n",
      "\n",
      "Beginning training epoch 2\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 0: 0.6128038763999939\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 10: 0.669556736946106\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 20: 0.594067394733429\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 30: 0.7616201043128967\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 40: 0.6950514316558838\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 50: 1.0521448850631714\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 60: 0.7331125736236572\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 70: 0.5297591090202332\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 80: 0.6282610893249512\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 90: 0.5547441840171814\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 100: 0.7912697196006775\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 110: 0.6098015308380127\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 120: 0.7405208349227905\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 130: 0.55177241563797\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 140: 0.7784461975097656\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 150: 0.4292810559272766\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 160: 0.4823833703994751\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 170: 0.9130452871322632\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 180: 0.7176219820976257\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 190: 0.5293598175048828\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 200: 0.518994152545929\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 210: 0.47482290863990784\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 220: 0.5054362416267395\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 230: 0.6273232698440552\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 240: 0.5226945281028748\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 250: 0.5583279132843018\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 260: 0.640810489654541\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 270: 0.5502273440361023\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 280: 0.6232556104660034\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 290: 0.9344416260719299\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 300: 0.6092675924301147\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 310: 0.5854867696762085\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 320: 0.6923655271530151\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "    loss at batch 330: 0.6325126886367798\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n",
      "Train Pytorch CUDA NOTAVAIL\n"
     ]
    }
   ],
   "source": [
    "# Start the training session\n",
    "\n",
    "cmdargs = [\"--train\",\n",
    "                  \"--sardir\",\"%s/SAR-Intensity\" % train_path,\n",
    "                  \"--opticaldir\",\"%s/PS-RGB\" % train_path,\n",
    "                  \"--labeldir\",\"%s/geojson_buildings\" % train_path,\n",
    "                  \"--rotationfile\",\"%s/SummaryData/SAR_orientations.txt\" % train_path,\n",
    "                             \"--rotationfilelocal\",\"%s/SAR_orientations.txt\" % pretrain_path,\n",
    "                              \"--maskdir\", \"%s/masks\" % pretrain_path,\n",
    "                              \"--sarprocdir\", \"%s/sartrain\" % pretrain_path, \n",
    "                              \"--opticalprocdir\",\"%s/optical\" % pretrain_path,\n",
    "                              \"--traincsv\",\"%s/train.csv\" % pretrain_path,\n",
    "                              \"--validcsv\", \"%s/valid.csv\" % pretrain_path,\n",
    "                              \"--opticaltraincsv\", \"%s/opticaltrain.csv\" % pretrain_path,\n",
    "                              \"--opticalvalidcsv\", \"%s/opticalvalid.csv\" % pretrain_path,\n",
    "                              \"--testcsv\",\"%s/test.csv\" % pretrain_path,\n",
    "                              \"--yamlpath\",\"%s/sar.yaml\" % outpath,\n",
    "                              \"--opticalyamlpath\",\"%s/optical.yaml\" % outpath,\n",
    "                              \"--modeldir\",\"%s/weights\" % outpath,\n",
    "                              \"--testprocdir\",\"%s/sartest\" % outpath,\n",
    "                              \"--testoutdir\",\"%s/inference_continuous\" % outpath,\n",
    "                              \"--testbinarydir\",\"%s/inference_binary\" % outpath,\n",
    "                              \"--testvectordir\",\"%s/inference_vectors\" % outpath,\n",
    "                              \"--rotate\",\n",
    "                              \"--transferoptical\",\n",
    "                              \"--mintrainsize\",\"20\",\n",
    "                              \"--mintestsize\",\"80\"]\n",
    "args = baseline_wrap.parse_args(cmdargs)\n",
    "#print(args)\n",
    "#import importlib\n",
    "#importlib.reload(baseline_wrap)\n",
    "baseline_wrap.invoke(outpath, '../../data/spacenet6/pretrain', args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
